---
title: La régression linéaire
sidebar: auto
author:
  - Cheryl Kouadio
bibliography: ../../references.bib
---

La régression linéaire est une méthode d'apprentissage supervisé qui vise à évaluer, lorsqu'il existe, la relation linéaire entre une variable d'intérêt et des variables explicatives.


# Le modèle

Pour un ensemble $(y_i,x_i)$ de données constitué de n échantillons iid (indépendant et identiquement distribué), le  modèle de regression linéaire s'écrit comme suit :
$$
y_i= \beta_0 + \beta_1 x_{i1} + \dots + \beta_p x_{ip} + \xi_i
$$

où $y_i$ est la variable cible, $x_{i1}, \dots, x_{ip}$ sont les variables explicatives et $\xi_i$ est l'erreur, l'information que les autres variables explicatives ne donnent pas. 

## Hypothèses

### Relation Linéaire
L'hypothèse fondamentale de la régression linéaire est l'existence d'une relation linéaire entre la variable cible et les variables explicatives. Pour s'assurer de la pertinence de cette hypothèse avant de procéder à la régression linéaire, il est recommandé de :

- **Visualisation des données** : Utiliser un nuage de points pour chaque paire de variables explicatives et la variable cible. Cette visualisation aide à détecter la présence et la forme de relations potentielles, guidant ainsi la décision d'utiliser ou non un modèle linéaire.
- **Tests de corrélation** :
  - **Corrélation de Pearson** : Ce test mesure la corrélation linéaire entre deux variables, fournissant un coefficient dont la valeur absolue proche de 1 indique une forte corrélation linéaire.
  - **Corrélation de Spearman** : Ce test de rang est utilisé pour évaluer la corrélation monotone entre deux variables, utile notamment lorsque les données ne respectent pas les conditions de normalité requises pour le test de Pearson.

### Propriétés des Erreurs
Pour que les estimations des paramètres du modèle linéaire soient fiables, tles erreurs du modèle, représentées par $\xi_i$, doivent répondre à plusieurs critères :

- **Erreurs centrées** : La moyenne attendue des erreurs doit être nulle, soit $E[\xi_i] = 0$. Cela signifie que le modèle ne présente pas de biais systématique dans les prédictions.
- **Homoscédasticité** : La variance des erreurs doit être constante pour toutes les observations, exprimée par $V[\xi_i] = \sigma^2$. Cette propriété garantit que la précision des estimations est uniforme à travers la gamme des valeurs prédites.
- **Décorrélation des erreurs** : Les erreurs doivent être mutuellement indépendantes, c’est-à-dire que la covariance entre toute paire d'erreurs est nulle, $Cov(\xi_i, \xi_j) = 0$ pour $1\leq i \neq j \leq n$. Cette condition est essentielle pour éviter les biais dans les estimations des paramètres et pour que les tests statistiques sur les coefficients soient valides.

