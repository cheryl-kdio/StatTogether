{
  "hash": "2e8e3abb0ff548f5a8d134cbe97cdf03",
  "result": {
    "markdown": "---\ntitle: \"Tp noté - Apprentissage supervisé 2A\"\nauthor: \"Cheryl Kouadio\"\n---\n\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-1_6b45d1618a8d249b63a0536c4a5f2ad7'}\n\n```{.r .cell-code}\nset.seed(2023)\nlibrary(data.table)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(rpart)\nlibrary(rpart.plot)\nlibrary(caret)\nlibrary(ranger)\nlibrary(reticulate)\n```\n:::\n\n\n# Partie 1 - Chargement du jeu de données, analyse exploratoire\n\nLe jeu de données comprend des mesures effectuées 1599 vins. Ainsi, pour chaque vin, il a été mesuré 12 caractéristiques à savoir :\n\n-   L'acidité fixe (`fixed.acidity`)\n-   L'acidité volatile (`volatile.acidity`)\n-   L'acide citrique (`citric.acid`)\n-   Le sucre résiduel (`residual.sugar`)\n-   Le chlorure (`chlorides`)\n-   Le dioxyde de soufre libre(`free.sulfur.dioxide`)\n-   Le dioxyde de soufre total(`total.sulfur.dioxide`)\n-   La densité(`density`)\n-   Le pH allant de 0 à 14 (plus le pH est bas, plus le vin est acide)\n-   Le sulfate (`sulphates`)\n-   L'alcool (`alcohol`)\n-   La note sur la qualité du vin (`quality`).\n\nIl s'agira à la fin de ce TP de prédire une note pour chaque vin, reflétant sa qualité.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-2_b68e06208d800a7fc6296a639993ffb0'}\n\n```{.r .cell-code}\n#chargement des données\nwine_quality<-fread(\"Donnees_qualite_vins.csv\")\nnames(wine_quality)<-make.names(names(wine_quality))\n```\n:::\n\n\n## 1. Analyse descriptive univariée des variables\n\nAvant toute analyse descriptive de nos variables, il est important de vérifier que nos données ne contiennent aucune valeur manquante.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-3_dad10333c52667ec78e6e56117ab0f80'}\n\n```{.r .cell-code}\ncolSums(is.na(wine_quality))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       fixed.acidity     volatile.acidity          citric.acid \n                   0                    0                    0 \n      residual.sugar            chlorides  free.sulfur.dioxide \n                   0                    0                    0 \ntotal.sulfur.dioxide              density                   pH \n                   0                    0                    0 \n           sulphates              alcohol              quality \n                   0                    0                    0 \n```\n:::\n:::\n\n\nNous constatons que nos données ne contiennent aucune valeur manquante. Cette constatation est prometteuse car elle signifie que nos données sont **complètes**, ce qui est essentiel pour la construction d'un modèle de régression fiable.\n\n### 1.1 Qualité du vin (quality)\n\nLa variable `quality` constitue ici notre variable d'intérêt pour la régression à effectuer. Cette variable est discrète et prend des valeurs entières entre 3 (pour un vin de mauvaise qualité) et 8 (pour un vin de meilleur qualité).\n\nEn moyenne, les vins ont une note de $5,636$. De fait, nous constatons qu'au moins 50% des vins ont une note supérieur à la moyenne.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-4_4c58a832baa612e2b4286df51e99512a'}\n\n```{.r .cell-code}\nggplot(wine_quality,aes(x=quality))+\n  geom_bar()+\n  theme_bw()+\n  labs(title =\"Répartition de la qualité des vins\",x=\"qualité des vins\", y=\"nombre de vins\")+theme(aspect.ratio = 1.5)\n```\n\n::: {.cell-output-display}\n![](Tp_Cheryl_Kouadio_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nround(prop.table(table(wine_quality$quality)),2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n   3    4    5    6    7    8 \n0.01 0.03 0.43 0.40 0.12 0.01 \n```\n:::\n:::\n\n\nPar ailleurs,la majorité de nos vins obtient une note de 5 (43% des vins) ou 6 (40% des vins).\n\n::: box\nNous pourrons considérer cette variable comme étant catégorielle étant donnée le faible nombre de valeurs qu'elle prend. Le problème posé ici peut être donc vu comme un problème de classification tout comme un problème de régression.\n:::\n\n### 1.2 Acidité fixe (fixed.acidity)\n\nL'acidité fixe dans un vin correspond à la quantité d'acides fixes présents naturellement dans le vin. L'ensemble des vins de notre jeu de données présentent une acidité fixe moyenne de $8,32$. Cependant, il est intéressant de noter que la médiane de l'acidité fixe se situe à 7,90, ce qui indique qu'un peu plus de la moitié des vins sont plus acides que d'autres.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-5_809116fe937168a02095975ec2ddbb8c'}\n\n```{.r .cell-code}\nggplot(wine_quality,aes(y=fixed.acidity))+\n  geom_boxplot()+\n  theme_bw()+\n  labs(title =\"Niveau d'acidité fixe des vins\")+\n  theme(aspect.ratio = 1)\n```\n\n::: {.cell-output-display}\n![](Tp_Cheryl_Kouadio_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nDe plus, l'acidité fixe des vins est compris entre $4,60$ à $15,90$ avec une dispersion de $\\sigma^2=3.03$. Cette variation signifie que certains vins affichent une acidité plus élevée que d'autres, ce qui contribue à une grande diversité au sein de l'échantillon.\n\n### 1.3 Acidité Volatile (volatile.acidity)\n\nL'acidité volatile dans un vin correspond à la quantité d'acides volatils qu'il contient, c'est à dire des acides qui sont capables de s'évaporer après la vinification.\n\nDans notre jeu de données, nous constatons que l'acidité volatile s'étend de 0,1200 à 1,5800, avec une moyenne d'environ 0.5278. Ainsi, certains vins présentent une acidité volatile plus élevée que d'autres.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-6_3fe1762f0ac5b6ce8d35f7cd0cebd755'}\n\n```{.r .cell-code}\nggplot(wine_quality,aes(y=volatile.acidity))+\n  geom_boxplot()+\n  theme_bw()+\n  labs(title =\"Niveau d'acidité volatile des vins\")+\n  theme(aspect.ratio = 1)\n```\n\n::: {.cell-output-display}\n![](Tp_Cheryl_Kouadio_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n### 1.4 Acide Citrique (citric.acid)\n\nLa teneur en acide citrique varie de 0 à 1, avec une moyenne d'environ 0,271. Tout comme l'aciditité fixe, 50% des vins ont un niveau d'acide citrique inférieur à la moyenne.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-7_0a5238da3e8951aa9fd6ec1ec291496c'}\n\n```{.r .cell-code}\nsummary(wine_quality$citric.acid)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.090   0.260   0.271   0.420   1.000 \n```\n:::\n:::\n\n\nOn observe également une certaine variabilité des teneurs en acide citrique dans cet échantillon. En effet, le premier quart des observations a une acidité inférieure à 0.09 , tandis que le dernier quart a une acidité supérieure à 0.42. De fait, certains vins sont quasi dépourvus en acide citrique tandis que d'autres sont riches en cet acide.\n\n### 1.5 Sucre Résiduel (residual.sugar)\n\nLe sucre résiduel fait référence à la quantité de sucre restant dans un vin après la fermentation alcoolique.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-8_b07e34d15f194d02e2ff3ae2725cc614'}\n\n```{.r .cell-code}\nsummary(wine_quality$residual.sugar)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.900   1.900   2.200   2.539   2.600  15.500 \n```\n:::\n:::\n\n\nOn constate une certaine variabilité des teneurs en sucre résiduel de nos vins. En effet, le premier quartile à 1,9 montre que 25% des vins ont un sucre résiduel inférieur à cette valeur. A l'opposé, 25% dépassent 2,6 d'après le troisième quartile.\n\nBien que la majorité se concentre autour de la moyenne aux alentours de 2-3 , certains vins sont très faiblement dotés en sucre résiduel (minimum de 0,9) tandis que d'autres en contiennent des doses importantes, pouvant aller jusqu'à 15,5 (max).\n\n### 1.6 Chlores (chlorides)\n\nLe chlore (chloride) est un élément chimique présent naturellement dans le vin. Il s’agit de l’ion chlorure $Cl-$.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-9_385077ccfb46717d785777810236c416'}\n\n```{.r .cell-code}\nsummary(wine_quality$chlorides)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.01200 0.07000 0.07900 0.08747 0.09000 0.61100 \n```\n:::\n:::\n\n\nDans notre jeu de données, nous constatons que 25% des vins ont une teneur inférieure à 0.07 L. De plus, la moitié des vins ont moins de 0,079 de teneur en chlore, soit moins de la moyenne qui est de 0,08.\n\nLa majorité des vins(50%) ont une concentration en chlorure située entre 0,07 et 0,09 g/L, avec quelques valeurs extrêmes plus faibles et plus élevées.\n\n### 1.7 Dioxyde de Soufre Libre (free.sulfur.dioxide)\n\nLe dioxyde de soufre libre (SO2 libre) est une forme de dioxyde de soufre (SO2) que l’on trouve naturellement ou que l’on ajoute au vin. C’est la forme active du dioxyde de soufre dans le vin, essentielle pour sa conservation.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-10_7eb214725fa4ddc3b46caea305f3eb46'}\n\n```{.r .cell-code}\nggplot(wine_quality,aes(x=free.sulfur.dioxide))+\n  geom_histogram(bins=30)+\n  theme_bw()+\n  labs(title =\"Teneur en dioxide de soufre libre\")+\n  theme(aspect.ratio = 1)\n```\n\n::: {.cell-output-display}\n![](Tp_Cheryl_Kouadio_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nOn constate une variabilité importante des teneurs en dioxyde de soufre libre dans nos vins. Le premier quartile à 1 indique que 25% des vins ont une très faible teneur en dioxyde de soufre, (inférieure à 1) tandis que le troisième quartile à 21 révèle que 25% des vins ont une concentration supérieure à 21 en dioxyde de soufre libre. De fait, certains vins possèdent une teneur très élevée en ce dioxyde.\n\n### 1.8 Dioxyde de Soufre Total (total.sulfur.dioxide)\n\nLe dioxyde de soufre total (SO2 total) est l’autre forme de dioxyde de soufre dans le vin. Il est un composé chimique utilisé couramment comme additif dans le processus de vinification.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-11_33e2af76a145ec851cae88c8c832b948'}\n\n```{.r .cell-code}\nsummary(wine_quality$total.sulfur.dioxide)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   6.00   22.00   38.00   46.47   62.00  289.00 \n```\n:::\n:::\n\n\nIl y a une grande variabilité des teneurs en dioxyde de soufres totaux pour les vins de cet échantillon. En moyenne, les vins de notre échantillon ont une teneur de 46,47 ce qui est supérieur à la médiane qui s'élève à 38.\n\n### 1.9 Densité (density)\n\nLa densité du vin est généralement mesurée en gramme par centimètre cube (g/cm³).\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-12_d701b483cb5c81e21bb177f2c1f4fbb6'}\n\n```{.r .cell-code}\nsummary(wine_quality$density)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.9901  0.9956  0.9968  0.9967  0.9978  1.0037 \n```\n:::\n:::\n\n\nLa valeur minimale de 0.9901 indique la présence de vins avec une densité très faible. Le premier quartile à 0.9956 montre que 25% des vins ont une densité inférieure à ce seuil. La médiane à 0.9968 signifie que la moitié des observations sont en dessous de cette valeur. Le troisième quartile à 0.9978 révèle que 25% des vins ont une densité qui dépasse 0.9978. Enfin, la valeur maximale atteint 1.0037, démontrant l’existence de vins avec des densités très élevées.\n\n### 1.10 pH\n\nOn remarque d’emblée que les vins de cet échantillon présentent des pH relativement homogènes et resserrés. En effet, 50% des observations (l’intervalle entre le 1er et le 3e quartile) sont comprises entre 3,21 et 3,4. De plus, la moyenne de 3,311 et la médiane à 3,31 indiquent une distribution centrée.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-13_c5b16e9f46c73dd3ed9906521ec092f4'}\n\n```{.r .cell-code}\nggplot(wine_quality,aes(x=pH))+\n  geom_histogram(bins = 30)+\n  theme_bw()+\n  labs(title =\"Répartition du pH des vins\",x=\"pH\")+\n  theme(aspect.ratio = 1)\n```\n\n::: {.cell-output-display}\n![](Tp_Cheryl_Kouadio_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nCette faible dispersion des pH autour de la moyenne suggère une certaine cohérence des vins analysés en termes d’acidité. Quelques vins se démarquent avec un pH plus acide (minimum) ou plus basique (maximum), mais l’essentiel des échantillons affiche un pH entre 3,2 et 3,4.\n\n### 1.11 Sulfates (sulphates)\n\nLes sulfates, ou plus spécifiquement le dioxyde de soufre (SO2), sont couramment utilisés dans l’industrie vinicole comme additif.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-14_7f51bb9aae048378ebfdf650f1d99ea7'}\n\n```{.r .cell-code}\nggplot(wine_quality,aes(x=sulphates))+\n  geom_histogram(bins = 30)+\n  theme_bw()+\n  labs(title =\"Répartition du niveau de sulfate des vins\")+\n  theme(aspect.ratio = 1.5)\n```\n\n::: {.cell-output-display}\n![](Tp_Cheryl_Kouadio_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nOn observe pour les sulfates une distribution plus dispersée que pour le pH précédemment étudié. Bien que l’intervalle interquartile soit resserré entre 0.55 et 0.73, on observe une valeur minimal de sulphates de 0.33 à 2.00 au maximum.\n\nCette amplitude plus large induit une moyenne de 0.6581 plus éloignée de la médiane à 0.62. Cette variabilité plus marquée des sulfates pourrait supposer que les vins analysés présentent des concentrations diverses en cet élément. Si la majorité affiche une teneur groupée entre 0.55 et 0.73, certains vins s’en distinguent avec des sulfates très faibles ou au contraire particulièrement élevés.\n\n### 1.12 Alcool (alcohol)\n\nLa teneur en alcool est l’une des caractéristiques les plus importantes du vin.\n\nOn constate que la concentration en alcool présente une distribution relativement étalée au sein de l’échantillon. La moyenne de 10.42, légèrement supérieure à la médiane de 10.2, confirme une asymétrie positive de la distribution. De fait, certains vins se démarquent donc avec des degrés d’alcool marqués, au-delà de 14°, quand d’autres restent sur une teneur plus modérée.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-15_7db318ca61bb808725bb0f2b7c509071'}\n\n```{.r .cell-code}\nggplot(wine_quality,aes(x=alcohol))+\n  geom_density() +\n    geom_histogram(bins = 30)+\n  theme_bw()+\n  labs(title =\"Concentration en alcool\")+\n    theme(aspect.ratio = 1.5)\n```\n\n::: {.cell-output-display}\n![](Tp_Cheryl_Kouadio_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n## 2. Analyse visuelle bivariée entre les variables\n\n### 2.1 Les relations entre les variables explicatives :\n\nL’analyse graphique des relations entre les variables explicatives montre que la majorité des couples de variables ne présentent pas de relation linéaire visible. Cependant, quelques exceptions apparaissent avec des corrélations linéaires visuelles notables :\n\n-   Une relation positive entre fixed.acidity (acidité fixe) et citric.acid (acidité citrique) : quand l’acidité fixe augmente, l’acidité citrique a tendance à augmenter aussi.\n\n-   Une relation linéaire positive également entre fixed.acidity et density (densité) : plus l’acidité fixe est élevée, plus la densité du vin a tendance à être importante.\n\n-   A l’inverse, une relation linéaire négative semble se dégager entre fixed.acidity et le pH des vins : le pH diminue lorsque l’acidité fixe croît.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-16_dfed2885df970f455257c91db99ec07d'}\n\n```{.r .cell-code}\npairs(wine_quality[,-12], pch = \".\",upper.panel = NULL, \n      main=\"Visualisation des relations entre les variables explicatives\")\n```\n\n::: {.cell-output-display}\n![](Tp_Cheryl_Kouadio_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n::: box\nCette analyse graphique préliminaire met en évidence quelques relations linéaires visuelles intéressantes entre certains couples de variables explicatives. Des analyses complémentaires comme des tests devraient être effectuées afin de confirmer et quantifier précisément ces relations.\n:::\n\n### 2.2 Les variables qui influent sur la qualité du vin\n\nPuisque la variable à prédire (la note du vin) est discrète avec de une étendue de valeurs prises basse, il est pertinent de la considérer comme une variable catégorielle pour l’analyse graphique. L’objectif étant d’évaluer visuellement l’influence des variables explicatives sur cette note qualitative, la représentation adaptée n’est pas un nuage de points.\n\nEn effet, un nuage de points convient pour analyser des relations continues entre variables quantitatives continues. La visualisation la plus appropriée consistera donc à représenter la distribution de chaque variable explicative en fonction des classes de la variable à prédire, à savoir les différentes notes de qualité des vins.\n\nOn utilisera pour cela des boîtes à moustaches (boxplots) pour chaque variable explicative, en utilisant les note de qualité comme modalité.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-17_329ae75df7aa1aa1280f15eb18a5f044'}\n\n```{.r .cell-code}\nwine_quality %>%\n  mutate(quality = as.factor(quality)) %>%\n  melt(id_vars='quality') %>%\n  ggplot(mapping=aes(x=quality, y=value)) +\n  geom_boxplot(outlier.size = 0.5)+\n  facet_wrap(~variable, scales=\"free\") +\n  labs(title='Boxplot selon la qualité des vins')\n```\n\n::: {.cell-output-display}\n![](Tp_Cheryl_Kouadio_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nL’analyse visuelle préliminaire semble mettre en évidence plusieurs variables potentiellement prédictives de la note de qualité des vins :\n\n-   La teneur en acide volatile (volatile.acidity) semble négativement corrélée aux bonnes notes de qualité de vins.\n\n-   L’acidité citrique (citric.acid) est quant à elle positivement corrélée à la note.\n\n-   Le degré d’alcool (alcohol) semble être positivement lié à la note de qualité.\n\n-   La densité (density) semble elle aussi négativement corrélée à la qualité du vin.\n\n-   Enfin, la concentration en sulfates (sulphates) est positivement corrélée à la note de qualité.\n\n::: box\nBien que nécessitant confirmation, ces relations visuelles fournissent de premières pistes intéressantes sur les facteurs qui influent potentiellement la qualité du vin. Par la suite, nous allons effectuer un modèle d'arbre cart de régression. Cela nous permettra d'avoir un indicateur sur les variables qui influent bel et bien sur la qualité du vin.\n:::\n\n# Partie 2 : Construction des échantillons, entraînement des modèles\n\n## 1. Construction des échantillons\n\nComme observé au 1.1, les notes de qualité des vins dans notre jeu de données présentent une distribution déséquilibrée, avec une forte majorité de vins ayant une note entre 5 et 6. Afin d’obtenir des échantillons représentatifs pour l’entraînement et les tests, nous devons **stratifier** les données en fonction de cette variable cible.\n\nNous allons ainsi constituer nos jeux de données de sorte à conserver la même proportion des différentes notes de qualité dans l’échantillon d’apprentissage et de test avec la fonction `createDataPartition` de la library `caret`. Cette stratification selon la variable cible permettra d’obtenir des échantillons représentatifs.\n\nPour le découpage, nous avons arbitrairement choisi d’allouer 70% des données à l’ensemble d’entraînement, qui servira à l’apprentissage du modèle prédictif. Les 30% restants formeront l’échantillon test, qui permettra d’évaluer la performance de nos différents modèles sur des données inconnues.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-18_c3bff9aaf1ba1d4a28a5919e7e3d027d'}\n\n```{.r .cell-code}\nset.seed(2023)\nsplitIndex <- createDataPartition(wine_quality$quality, p = 0.7, \n                                  list = FALSE)\n\n# Création des ensembles d'apprentissage et de test en maintenant la proportion de chaque niveau de qualité\ntrain <- wine_quality[splitIndex, ]\ntest <- wine_quality[-splitIndex, ]\n```\n:::\n\n\n## 2. Algorithme CART (Classification And Regression Trees)\n\n### 2.1 Entrainement de l'arbre CART\n\nL’acronyme CART signifie Classification And Regression Trees. Il désigne une méthode statistique qui construit des prédicteurs par arbre aussi bien en régression qu'en classification. Ici, il sera utilisé pour de la régression.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-19_2d241c5ce4bec75864e7f933867137a6'}\n\n```{.r .cell-code}\n#Entrainement d'un arbre CART\narbre_cart<-rpart(quality~.,data=train,method=\"anova\")\n```\n:::\n\n\nEn modèle CART, l'hyper paramètre à optimiser est la complexité qui permet l'élagage des arbres. En effet, lorsque l’arbre CART est maximal, notre prédicteur a une très grande variance et un biais faible. A contrario, lorsque l'arbre est constitué uniquement de la racine (qui engendre alors un prédicteur constant), on a a une très petite variance mais un biais élevé.\n\nL’élagage est une procédure de sélection de modèles, où les modèles sont les sous-arbres élagués de l’arbre maximal. Cette procédure minimise un critère pénalisé où la pénalité est proportionnelle au nombre de feuilles de l’arbre.\n\nSelon le graphique ci-dessous, la complexité permettant de faire un bon compromis biais-variance est une complexité $0,01$. Nous allons donc re-entrainé notre arbre CART avec cet hyper paramètre.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-20_23892a9f9d43d122b45c71e9d0819ac8'}\n\n```{.r .cell-code}\nplotcp(arbre_cart)\n```\n\n::: {.cell-output-display}\n![](Tp_Cheryl_Kouadio_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-21_5c9d4b8f0259d6430ea5bc4bf4a07d56'}\n\n```{.r .cell-code}\n#Re-entrainement de l'arbre CART\narbre_cart<-rpart(quality~.,data=train,method=\"anova\",cp=0.01)\n```\n:::\n\n\n### 2.2 Divisions équireductrices et equidivisantes\n\nL'entrainement de l'arbre CART sur notre échantillon d'apprentissage nous permet de prédire des nouvelles valeurs en se basant sur la connaissance de certaines valeurs de certaines variables.\n\nLe premier noeud formé par l'entrainement de l'arbre CART est le noeud racine qui contient toutes les 1120 observations. Cette première division est basée sur la teneur en alcool des vins de notre échantillon d'apprentissage.\n\nAinsi, si la teneur en alcool est inférieure à 10.525, alors l'observation va à gauche. C'est la meilleure division car elle offre la plus grande amélioration. Il existe également d'autres variables qui lorsqu'elles sont divisées à un certain seuil, fournissent la meilleure amélioration (diminution) de l'erreur (ou de l'impureté). Ce sont les divisions équiréductrices(**Primary splits**) comme sulphates, volatile.acidity etc.\n\nS'il manque des valeurs pour cette variable, l'arbre CART se basera sur d'autres variables comme des divisions équidivisantes (**Surrogate splits**) comme density, chlorides, etc., pour décider de la division et donc prédire un nouveau vin.\n\nPour prédire un nouveau vin pour lequel le taux d’alcool et la densité n’aurait pas été mesurée et serait donc manquants, l'arbre CART se basera donc sur la concentration en chlore pour effectuer la première coupure.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-22_c29e05f0c33f9e87ee81c585ea50c288'}\n\n```{.r .cell-code}\n# Afficher le résumé de l'apprentissage de notre modèle\n#summary(arbre_cart) \n```\n:::\n\n\n```         \n### Extrait de la sortie de summary(arbre_rpart) ###\nNode number 1: 1120 observations,    complexity param=0.1738621\n  mean=5.632143, MSE=0.6486097 \n  left son=2 (684 obs) right son=3 (436 obs)\n  Primary splits:\n      alcohol          < 10.525   to the left,  improve=0.17386210, (0 missing)\n      sulphates        < 0.645    to the left,  improve=0.12939930, (0 missing)\n      volatile.acidity < 0.405    to the right, improve=0.12619650, (0 missing)\n      citric.acid      < 0.295    to the left,  improve=0.07021357, (0 missing)\n      density          < 0.995565 to the right, improve=0.06232750, (0 missing)\n  Surrogate splits:\n      density          < 0.995575 to the right, agree=0.763, adj=0.392, (0 split)\n      chlorides        < 0.0685   to the right, agree=0.686, adj=0.193, (0 split)\n      volatile.acidity < 0.375    to the right, agree=0.666, adj=0.142, (0 split)\n      fixed.acidity    < 6.75     to the right, agree=0.651, adj=0.103, (0 split)\n      sulphates        < 0.705    to the left,  agree=0.640, adj=0.076, (0 split)\n```\n\n### 2.3 Visualisation du résultat\n\nL'arbre CART nous permet de d'avoir la prédiction de la qualité du vin avec de nouvelle valeur. L'arbre démarre avec la valeur de 5.6, qui est la note moyenne de tous les vins et se lit assez intuitivement. Selon l'arbre, les variables les plus informatives sur la qualité du vin sont la concentration en alcool, en sulfates, l'acidité volatile ainsi que le pH.\n\nPar exemple, si nous avons un nouveau vin avec les caractéristiques suivantes `alcohol = 11.5`, `pH = 2`, `free.sulfur.dioxide = 7.6`, `sulphates =0.42`, `volatile.acidity = 0.98`, nous aurions obtenu la note de $4$.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-23_2fabfd3f28df375db3a7f4379f340ed3'}\n\n```{.r .cell-code}\nrpart.plot(arbre_cart)\n```\n\n::: {.cell-output-display}\n![](Tp_Cheryl_Kouadio_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n### 2.4 Erreur de généralisation et comparer les vraies valeurs aux prédictions\n\nL'Erreur Quadratique Moyenne est la métrique de performance que nous utiliserons pour évaluer la qualité des modèles de régression. Elle mesure la moyenne des carrés des erreurs, c'est-à-dire la moyenne des carrés des différences entre les valeurs prédites et les valeurs réelles. Plus celle-ci est faible, plus le modèle est bien ajusté à nos données et donc plus précis.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-24_5c3a34a73a85851470372cc3138578a2'}\n\n```{.r .cell-code}\n#Erreur de prédictions\npredictions_cart <- predict(arbre_cart, test)\nmse <- mean((predictions_cart - test$quality )^2) \nprint(paste(\"Erreur de généralisation (RMSE) : \", sqrt(mse)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Erreur de généralisation (RMSE) :  0.678171784937612\"\n```\n:::\n:::\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-25_0d5f1df84ce25938ee21647a49a30996'}\n\n```{.r .cell-code}\ndata <- data.frame(TrueValues = test$quality, PredictedValues = predictions_cart)\n\nggplot(data, aes(x = TrueValues, y = PredictedValues)) +\n  geom_point() +\n  theme_minimal() +\n  labs(x = \"vraies valeurs\", y = \"prédictions\", title = \"Predictions de la qualité du vin\")\n```\n\n::: {.cell-output-display}\n![](Tp_Cheryl_Kouadio_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n### 2.5 Robustesse\n\nLes arbres CART, bien que puissants pour la modélisation et la visualisation, présentent une sensibilité notable à de petits changements dans les données. Cela peut se traduire par une grande variabilité dans la structure de l'arbre pour de légères modifications du jeu de données.\n\nEn observant les quatre arbres ci dessous, nous pouvons constater que chaque arbre diffère dans sa structure, ses nœuds de division et ses critères de division, malgré le fait qu'ils soient issus de jeux de données très similaires ou de sous-ensembles de données. Cette variabilité souligne le **manque de robustesse** des arbres CART.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-26_cdbc6fa1d7d599802b65cf47779cbcd6'}\n\n```{.r .cell-code}\nnum_trees <- 4  # Nombre d'arbres à générer\n\n# Créez une liste pour stocker les arbres\narbres <- list()\n\n# Générez et stockez les arbres dans la liste\nfor (i in 1:num_trees) {\n  index <- createDataPartition(wine_quality$quality, p = 0.5, list = FALSE)\n  training_sample <- wine_quality[index, ]\n  arbres[[i]] <- rpart(quality ~ ., data = training_sample)\n}\n\npar(mfrow=c(2, 2))  # Crée une grille pour afficher plusieurs arbres\n\n# Affichez chaque arbre dans la grille\nfor (i in 1:num_trees) {\n  rpart.plot(arbres[[i]], main = paste(\"Arbre\", i))\n}\n```\n\n::: {.cell-output-display}\n![](Tp_Cheryl_Kouadio_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n::: box\nEn pratique, pour obtenir des modèles plus robustes et moins sensibles aux variations, on utilise souvent les forêts aléatoires. Les forêts aléatoires, en combinant plusieurs arbres CART (où chaque arbre est formé à partir d'un sous-ensemble de données et d'un sous-ensemble de variables), permettent de \"moyenner\" les prédictions et d'atténuer les effets des instabilités individuelles des arbres.\n:::\n\n## 3. Forêt aléatoire\n\n### 3.1 Validation croisée\n\nLe package ranger est utilisé pour entraîner des forêts aléatoires. Voici quelques hyperparamètres importants de ranger que vous pouvez ajuster :\n\n-   mtry: Nombre d'arbre à insérer dans la forêt aléatoire\n-   min.node.size: Taille minimale du nœud (critère de changement d'un noeud en feuille)\n-   splitrule: le critère de pureté (\"gini\", \"extratrees\", \"variance\" ,etc.).\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-27_98a7b6821f4e07126e0a9f4f0f208828'}\n\n```{.r .cell-code}\nmodelLookup(\"ranger\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"model\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"parameter\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"label\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"forReg\"],\"name\":[4],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"forClass\"],\"name\":[5],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"probModel\"],\"name\":[6],\"type\":[\"lgl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"ranger\",\"2\":\"mtry\",\"3\":\"#Randomly Selected Predictors\",\"4\":\"TRUE\",\"5\":\"TRUE\",\"6\":\"TRUE\",\"_rn_\":\"1\"},{\"1\":\"ranger\",\"2\":\"splitrule\",\"3\":\"Splitting Rule\",\"4\":\"TRUE\",\"5\":\"TRUE\",\"6\":\"TRUE\",\"_rn_\":\"2\"},{\"1\":\"ranger\",\"2\":\"min.node.size\",\"3\":\"Minimal Node Size\",\"4\":\"TRUE\",\"5\":\"TRUE\",\"6\":\"TRUE\",\"_rn_\":\"3\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nAfin de les optimiser, nous allons réaliser une validation croisée.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/cv_bdcb7f62861e66bd1d5b977f9f02b200'}\n\n```{.r .cell-code}\n# Configuration de la validation croisée\ncontrol <- trainControl(method = \"cv\", number = 5)\n\n# Nouvelle grille d'hyperparamètres\ngrid <- expand.grid(\n  mtry = 1:10,\n  splitrule = c(\"variance\", \"extratrees\"),\n  min.node.size =1:5\n)\n\n# modèle via validation croisée\nforet_aleatoire <- train(\n  quality ~ .,\n  data = train,\n  method = \"ranger\",\n  trControl = control,\n  tuneGrid = grid\n)\n\nforet_aleatoire$bestTune\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"mtry\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"splitrule\"],\"name\":[2],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"min.node.size\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"8\",\"2\":\"extratrees\",\"3\":\"1\",\"_rn_\":\"76\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nNous avons utilisé l'erreur quadratique moyenne (RMSE) pour choisir le meilleur modèle par validation croisée. Les hyperparamètres optimaux sont `mtry = 6`, `splitrule = extratrees`, et `min.node.size = 2`, ce qui assure un bon équilibre entre performance et risque de surajustement.\n\n### 3.2 Re-entrainement du modèle\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-28_4cef4662b757552cd5edd8f4a2fadb50'}\n\n```{.r .cell-code}\n# Re-entrainement du modele avec valeurs optimales\nforet_aleatoire_final <- ranger(quality ~ ., \n                        data = train, \n                        mtry = foret_aleatoire$bestTune$mtry, \n                        splitrule = foret_aleatoire$bestTune$splitrule,\n                        min.node.size = foret_aleatoire$bestTune$min.node.size, \n                        importance = 'permutation')\n```\n:::\n\n\nSelon notre modèle de forêt aléatoire, l'alcool est de loin la variable la plus influente pour prédire la qualité du vin, suivi de l'acidité volatile et du sulfate etc. Cela correspond plus ou moins aux variables que nous avons identifié dans l'analyse visuelle préliminaire 2.2 .\n\nLes autres variables comme le chlorures et le sucre résiduel ont une moindre influence sur la qualité du vin. Ces résultats peuvent orienter nos prochains tests sur les facteurs clés affectant la qualité du vin.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-29_55f99e9f8de603ada46a16e2f79e66ce'}\n\n```{.r .cell-code}\n# Visualisation de l'importance des variables\nsort(foret_aleatoire_final$variable.importance, decreasing=T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             alcohol     volatile.acidity            sulphates \n          0.29968914           0.13309690           0.11818299 \ntotal.sulfur.dioxide              density          citric.acid \n          0.06834531           0.06113796           0.05774871 \n       fixed.acidity                   pH  free.sulfur.dioxide \n          0.04428113           0.03737898           0.03737879 \n           chlorides       residual.sugar \n          0.03435503           0.02516916 \n```\n:::\n:::\n\n\n### 3.3 Erreur de généralisation et erreur Out-Of-Bag\n\nL'erreur OOB est une estimation de l'erreur de généralisation obtenue en utilisant chaque observation pour évaluer un modèle qui n'a pas été formé avec cette observation. C'est l'un des avantages des forêts aléatoires; elles fournissent une estimation interne de l'erreur de généralisation.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-30_68a773e99caafc8e73ed3ac8b24bf1b3'}\n\n```{.r .cell-code}\npredictions_rf <- predict(foret_aleatoire_final, data = test)$predictions\nmse <- mean((predictions_rf - test$quality)^2)\nprint(paste(\"Erreur de généralisation (MSE): \", mse))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Erreur de généralisation (MSE):  0.336074897703549\"\n```\n:::\n\n```{.r .cell-code}\nprint(paste(\"Erreur Out-Of-Bag (OOB): \", foret_aleatoire_final$prediction.error))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Erreur Out-Of-Bag (OOB):  0.342473480056595\"\n```\n:::\n:::\n\n\nNous constatons qu'il y a une faible différence entre l'erreur de généralisation et l'erreur Out-Of-Bag (environ $0,01$).\n\nLa proximité de ces deux erreurs suggère que notre modèle de forêt aléatoire est robuste et généralise bien aux nouvelles données, sans signe apparent de sur ajustement.\n\nEn bref, notre modèle semble performant et fiable pour la prédiction de la qualité du vin.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-31_83ff2cfdf1d1d19be6b46be964bc60f2'}\n\n```{.r .cell-code}\ndata <- data.frame(TrueValues = test$quality, PredictedValues = predictions_rf)\n\nggplot(data, aes(x = TrueValues, y = PredictedValues)) +\n  geom_point() +\n  theme_minimal() +\n  labs(x = \"vraies valeurs\", y = \"prédictions\", title = \"Predictions de la qualité du vin\")\n```\n\n::: {.cell-output-display}\n![](Tp_Cheryl_Kouadio_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\n### 3.4 MDA importance (Mean decreasing accuracy)\n\nL’idée principale de la MDA repose sur le fait que si une variable explicative n’est pas importante pour prédire la cible, qu’on la prenne en compte ou non dans la construction de la forêt ne devrait pas changer l’erreur de généralisation.\n\nElle se calcule de la manière suivante :\n\n$$MDA(X_j) = \\frac{1}{n_{\\text{test}}} \\sum_{i=1}^{n_{\\text{test}}} l(y^*_i, \\frac{1}{B} \\sum_{b=1}^{B} g^{(-j)}_b(x^*_i)) - l(y^*_i, \\frac{1}{B} \\sum_{b=1}^{B} g_b(x^*_i)) $$ où $g^{-j}_b$ désigne la forêt aléatoire construite sans la j-ième variable explicative.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/mda_c891c53ae5db1d15fe3c48fdfa6c3ca5'}\n\n```{.r .cell-code}\nset.seed(123)\nB <- foret_aleatoire_final$num.trees\nn_test <- nrow(test)\n  \noriginal_preds <- predict(foret_aleatoire_final, data = test)$predictions\noriginal_loss <- mean((original_preds - test[[\"quality\"]])^2) # MSE\n  \nfeature_names <- names(test)\nfeature_names <- feature_names[feature_names != \"quality\"]\nMDA_values <- numeric(length(feature_names))\n  \n  \nfor(j in seq_along(feature_names)) {\n  temp_data <- train[, -j, with = FALSE]\n    \n  temp_forest <- ranger(quality ~., data = temp_data, num.trees = B)\n\n  permuted_preds <- predict(temp_forest, data = test)$predictions\n  permuted_loss <- mean((permuted_preds - test$quality)^2) # MSE après suppression de variable j\n\n  MDA_values[feature_names[j]] <- (permuted_loss - original_loss) \n}\n  \nsort(MDA_values[MDA_values != 0],decreasing = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           sulphates              alcohol     volatile.acidity \n        0.0366279588         0.0264460487         0.0144637845 \ntotal.sulfur.dioxide              density        fixed.acidity \n        0.0075565892         0.0073128653         0.0051167717 \n                  pH            chlorides       residual.sugar \n        0.0050919154         0.0034444456         0.0034389022 \n         citric.acid  free.sulfur.dioxide \n        0.0021225963         0.0009107246 \n```\n:::\n:::\n\n\nLa sortie MDA montre l'importance des variables dans un modèle de forêt aléatoire. Les \"sulphates\" et \"alcohol\" ont les valeurs MDA les plus élevées, ce qui signifie qu'ils sont les plus importants pour la précision du modèle. Les variables comme \"total.sulfur.dioxide\" et \"density\" ont une importance moindre mais intéressante à savoir.\n\nA l'inverse, des variables comme \"fixed.acidity\" et \"citric.acid\" etc. ont des valeurs MDA négatives, cela signifirait que les supprimer du modèle ferait baisser notre erreur de généralisation ce qui pourrait indiquer qu'elles ne sont pas très utiles dans ce modèle.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-32_1bd34c218e4d96d3abcf0cbfe73edb20'}\n\n```{.r .cell-code}\nsort(foret_aleatoire_final$variable.importance,decreasing = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             alcohol     volatile.acidity            sulphates \n          0.29968914           0.13309690           0.11818299 \ntotal.sulfur.dioxide              density          citric.acid \n          0.06834531           0.06113796           0.05774871 \n       fixed.acidity                   pH  free.sulfur.dioxide \n          0.04428113           0.03737898           0.03737879 \n           chlorides       residual.sugar \n          0.03435503           0.02516916 \n```\n:::\n:::\n\n\nDans la sortie d'importance de notre modèle constitué de toutes les variables explicatives, \"Alcohol\" prend la première place, suivi de \"sulphates\" et \"volatile.acidity\".\n\nDans les deux cas, \"alcohol\", \"sulphates\", et \"volatile.acidity\" se démarquent comme les variables les plus influentes, mais leur ordre d'importance change. \"Alcohol\" est devenu plus dominant dans la sortie donné directement par le modèle.\n\n# Bonus : Projection UMAP\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/importpy_a3007514f36e9473541a2c968d95fabe'}\n\n```{.python .cell-code}\nfrom umap import UMAP\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import silhouette_score\n```\n:::\n\n\n### 1. Validation croisée des paramètres UMAP\n\nUMAP, acronyme de \"Uniform Manifold Approximation and Projection\", est une méthode avancée de réduction de dimensionnalité.\n\nDans le cadre de notre étude utilisant un modèle de forêt aléatoire, cette technique nous permettra de simplifier la complexité de nos variables explicatives multidimensionnelles. Plus précisément, nous allons projeter ces variables sur deux axes seulement, facilitant ainsi leur visualisation et leur interprétation.\n\nEtant utilisé très souvent en apprentissage supervisé, nous allons faire une validation croisée afin de selectionner les meilleurs hyper paramètres de cette méthode.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/umap_547388130cdafa8490a056f561bb633d'}\n\n```{.python .cell-code}\ndf_train = pd.DataFrame(r.train)\n\n# Séparer la variable d'intérêt et les features\nX = df_train.drop(['quality'], axis=1)\ny = df_train['quality']\n\n# Normaliser les données\nscaler = StandardScaler()\nX_normalized = scaler.fit_transform(X)\n\n#Grid de paramètres à tester\nn_neighbors = [5, 10, 15, 20, 25]\nmin_dist = [0.1, 0.5, 1]\n\n# Entraîner UMAP pour toutes les combinaisons de paramètres\nbest_score = -1\nbest_params = {}\nfor k in n_neighbors:\n  for d in min_dist:\n      umap = UMAP(n_neighbors=k, min_dist=d)\n      projection = umap.fit_transform(X_normalized, y=y)\n\n      # Calculer le score silhouette\n      score = silhouette_score(projection, y)\n\n      if score > best_score:\n        best_score = score\n        best_params = {\"n_neighbors\": k, \"min_dist\": d}\n\nprint(\"Meilleurs paramètres:\", best_params)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMeilleurs paramètres: {'n_neighbors': 25, 'min_dist': 0.1}\n```\n:::\n\n```{.python .cell-code}\nprint(\"Score silhouette:\", best_score)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nScore silhouette: 0.48484257\n```\n:::\n:::\n\n\nDans UMAP, les axes n'ont pas de signification intrinsèque claire, car la méthode vise à préserver la structure locale des données plutôt qu'à expliquer la variance.\n\nToutefois, UMAP préserve les relations locales entre les points. Ainsi, la proximité entre les points dans la projection UMAP peut être interprétée comme une similarité dans l'espace de données d'origine.\n\nDans la projection de nos variables explicatives labellisées avec notre variables cible, nous constatons que les vins ayant eu une mauvaise note de qualité semble avoir des caractéristiques similaires qui diffèrent des vins ayant un bon qualité.\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/umap1_b74a196da850315bbc0494607a04d01e'}\n\n```{.python .cell-code}\n# Re entraîner le meilleur modèle\numap_model = UMAP(n_neighbors=best_params['n_neighbors'], min_dist=best_params['min_dist'], n_components=2, target_metric='l1')\nembedding = umap_model.fit_transform(X_normalized, y=y)\n\n# Visualisation\nplt.scatter(embedding[:, 0], embedding[:, 1], c=y, cmap='viridis')\nplt.colorbar(label='Quality')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<matplotlib.colorbar.Colorbar object at 0x7fcc5994cfa0>\n```\n:::\n\n```{.python .cell-code}\nplt.title('Projection UMAP ')\nplt.xlabel('UMAP 1')\nplt.ylabel('UMAP 2')\nplt.show()\n```\n\n::: {.cell-output-display}\n![](Tp_Cheryl_Kouadio_files/figure-html/umap1-1.png){width=672}\n:::\n:::\n\n\n### 2. Projection inverse et denormalisation\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/invproj_edb1a975e87ef155c989193c97999958'}\n\n```{.python .cell-code}\nimport numpy as np\n\n# Déterminer les limites de l'espace projeté\nx_min, x_max = embedding[:, 0].min() - 1, embedding[:, 0].max() + 1\ny_min, y_max = embedding[:, 1].min() - 1, embedding[:, 1].max() + 1\n\n# Créer une grille 100x100\nxx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n                     np.linspace(y_min, y_max, 100))\n\n# Aplatir la grille pour l'inverse de la transformation\ngrid = np.c_[xx.ravel(), yy.ravel()]\n\n# Calculer la projection inverse\ninverse_proj = umap_model.inverse_transform(grid)\n\n# Dé-normaliser les valeurs\ninverse_proj_denorm = scaler.inverse_transform(inverse_proj)\n```\n:::\n\n\n### 3. Prédictions de la forêt aléatoire pour ces points\n\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/predinv_03451e5a628b77df16c278308bcff71a'}\n\n```{.r .cell-code}\ninverse_proj_denorm <- as.data.frame(py$inverse_proj_denorm)\ncolnames(inverse_proj_denorm)<-colnames(train[,-12])\npredictions_umap_denorm<- predict(foret_aleatoire_final, data = inverse_proj_denorm)$predictions\n```\n:::\n\n::: {.cell hash='Tp_Cheryl_Kouadio_cache/html/unnamed-chunk-33_4b044b447998dff52f06e28b13103c2b'}\n\n```{.python .cell-code}\n# Transformer les prédictions en une matrice 100x100\npredictions = np.array(r.predictions_umap_denorm).reshape(100, 100)\n\n# Visualiser les prédictions dans l'espace UMAP\nplt.scatter(inverse_proj_denorm[:, 0], inverse_proj_denorm[:, 1], c=predictions.ravel(), cmap='viridis')\nplt.colorbar(label='Valeur de Prédiction')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<matplotlib.colorbar.Colorbar object at 0x7fcc5a1576a0>\n```\n:::\n\n```{.python .cell-code}\nplt.title('Prédictions de la Forêt Aléatoire dans l\\'Espace UMAP 2D')\nplt.xlabel('UMAP 1')\nplt.ylabel('UMAP 2')\nplt.show()\n```\n\n::: {.cell-output-display}\n![](Tp_Cheryl_Kouadio_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}