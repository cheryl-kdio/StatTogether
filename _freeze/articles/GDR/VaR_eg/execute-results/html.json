{
  "hash": "f052718c7e0338cdd53749d6615e065c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Application de la VaR\nsidebar: auto\nauthor:\n  - Cheryl Kouadio\ncategories:\n  - risque\n  - finance\n  - gdr\nexecute:\n  cache: true\nbibliography: ../../references.bib\n---\n\n# Introduction\n\nNous allons ici nous intéresser aux applications de la Value at Risk (VaR) en finance. La VaR est une mesure de risque qui permet d'estimer les pertes potentielles d'un portefeuille d'actifs financiers sur un horizon de temps donné, à un certain niveau de confiance. Elle est largement utilisée par les institutions financières pour évaluer et gérer les risques de marché, de crédit et de liquidité (cf. [Value at-Risk](var.qmd#sec-var-def))\n\n# Import des données\n\nNous utilisons les données du cac 40 du 01/03/1990 au 10/05/2024. Le CAC 40 (Cotation Assistée en Continu) est l'indice boursier le plus important de la Bourse de Paris. Son nom signifie que c'est un indice composé des 40 sociétés françaises les plus significatives et les plus liquides cotées sur Euronext Paris, qui est l'une des principales places boursières en Europe.\n\n::: {#68fb4e37 .cell execution_count=2}\n``` {.python .cell-code}\n# Librairie où importer les données\nimport yfinance as yf\n\ncac_40 = yf.Ticker(\"^FCHI\")\nts_data = cac_40.history(\"max\")\nts_data.index = ts_data.index.strftime('%Y-%m-%d')\nts_data.columns\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nIndex(['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits'], dtype='object')\n```\n:::\n:::\n\n\nNous  nous interesserons plus particulièrement au prix de la clôture, c'est à dire, le prix final de l'indice à la fin de la session de trading sur Euronext Paris, qui est la bourse où l'indice est coté. Celà reflète l'impact des nouvelles économiques, des performances des entreprises comprises dans l'indice, et des mouvements généraux du marché.\n\nDans notre cas, nous l'utiliserons pour calculer le rendement logarithmique.\nLe rendement logarithmique est le logarithme naturel du rapport entre le prix final et le prix initial d'un actif. Voici la formule mathématique :\n\n$$ R_{\\text{log}} = \\ln\\left(\\frac{P_{\\text{fin}}}{P_{\\text{début}}}\\right) $$\n\noù :\n\\begin{itemize}\n  \\item $R_{\\text{log}}$ est le rendement logarithmique,\n  \\item $\\ln$ représente le logarithme naturel,\n  \\item $P_{\\text{fin}}$ est la valeur de clôture de l'actif à la fin de la période,\n  \\item $P_{\\text{début}}$ est la valeur de clôture de l'actif au début de la période.\n\\end{itemize}\n\n::: {#3461a32a .cell execution_count=3}\n``` {.python .cell-code}\nimport warnings\nwarnings.filterwarnings('ignore')\nts_close = ts_data[[ 'Close']]\nimport pandas as pd\nimport numpy as np\n\n#Nbre de NA\nts_close.isna().sum()\n\nts_close['log_return'] = np.log(ts_close['Close'] / ts_close['Close'].shift(1))\nts_close = ts_close.dropna(subset=['log_return'])\nprint(ts_close.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Close  log_return\nDate                          \n1990-03-02  1860.0    0.015168\n1990-03-05  1874.0    0.007499\n1990-03-06  1872.0   -0.001068\n1990-03-07  1880.0    0.004264\n1990-03-08  1917.0    0.019490\n```\n:::\n:::\n\n\n# Test de stationarité du log-rendement\n\nPour utiliser le log rendement comme variable profit et perte (PnL : Profit and Loss) pour impléter la VaR, nous devons tester sa stationarité. En effet, la stationarité est une propriété importante des séries temporelles financières. Une série temporelle est dite stationnaire si ses propriétés statistiques telles que la moyenne, la variance et la covariance restent constantes au fil du temps.\n\n::: {#dd131826 .cell execution_count=4}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(6, 4))\n\nfig, ax = plt.subplots(1)\n\nax.set_xlabel('Date')\nax.set_ylabel('historical log returns')\nax.plot(ts_close.index, ts_close['log_return'], color='blue')\nax.tick_params(axis='y')\n\nplt.title('Historical Log-returns of CAC40')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n```\n<Figure size 576x384 with 0 Axes>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](VaR_eg_files/figure-html/cell-4-output-2.png){width=623 height=449}\n:::\n:::\n\n\nIl semblerait que la série des rendements logarithmiques est stationnaire. Nous allons tout de même en observant l'ACF et le PACF mais aussi effectuer un test de stationarité pour confirmer cette hypothèse.\n\n::: {#d387fb7f .cell execution_count=5}\n``` {.python .cell-code}\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfig, ax = plt.subplots(1,2, figsize=(8, 4))\nplot_acf(ts_close['log_return'].dropna(), ax=ax[0],title='ACF')\nplot_pacf(ts_close['log_return'].dropna(), ax=ax[1],title='PACF')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](VaR_eg_files/figure-html/cell-5-output-1.png){width=665 height=357}\n:::\n:::\n\n\nL'autocorrélation(ACF) et l'autocorrélation partielle(PACF) décroissent de manière exponentielle, ce qui indique que la série est stationnaire. \n\nPour plus de certitude, nous allons effectuer un test de Dickey-Fuller augmenté (ADF) pour tester la stationnaire dans la série :\n\n$$ \nH_0=\\rho = 1, \\alpha=0\n$$ \nDans le cas d'une série AR(1)($X_t = \\alpha + \\rho X_{t-1} + \\xi_t$) avec intercept, la série est non stationnaire si $\\rho = 1$ et stationnaire si $\\rho < 1.  Dans le cas contraire, il faudrait considérer la série de différences pour la rendre stationnaire.\n\n::: {#046e8c6a .cell execution_count=6}\n``` {.python .cell-code}\nfrom statsmodels.tsa.stattools import adfuller\nadf_result = adfuller(ts_close['log_return'].dropna(), regression='c')\nprint(f\"ADF Statistic: {round(adf_result[0],2)} and p-value: {adf_result[1]}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nADF Statistic: -40.83 and p-value: 0.0\n```\n:::\n:::\n\n\nLa p-value du test de dickey fuller est environ égale à 0, ce qui signifie que nous rejetons l'hypothèse nulle selon laquelle la série n'est pas stationnaire. Ainsi la série des log-rendements est stationnaire. Nous pouvons donc utiliser les rendements logarithmiques pour calculer la VaR à horizon 1 jour.\n\n# Modélisation de la VaR\n\nPour modéliser la VaR, nous considérons un échantillon d'apprentissage avec 75% des données et 25% pour l'échantillon de test.\n\n::: {#6ca3ab0e .cell execution_count=7}\n``` {.python .cell-code}\ntrain_size = int(len(ts_close)*0.75)\ntest_size = len(ts_close)-train_size\n\ntrain_close = ts_close.iloc[0:train_size,:].dropna()\ntest_close = ts_close.iloc[train_size:len(ts_close),:]\nprint(\"Taille de l'ensemble d'apprentissage :\", len(train_close))\nprint(\"Taille de l'ensemble de test :\", len(test_close))\npd.isna(train_close).sum()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTaille de l'ensemble d'apprentissage : 6510\nTaille de l'ensemble de test : 2170\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nClose         0\nlog_return    0\ndtype: int64\n```\n:::\n:::\n\n\n## VaR analytique\n\nPour rappel, la VaR analytique ou gaussienne est basée sur la distribution des rendements. Nous allons utiliser la distribution normale pour calculer la VaR à horizon 1 jour. La VaR à horizon 1 jour est définie comme suit :\n\n$$\nVaR = -\\mu_{PnL} + \\Phi^{-1}(\\alpha) \\times \\sigma_{PnL}\n$$\noù $\\Phi^{-1}(\\alpha)$ est le quantile de la distribution normale du PnL (Profit and Loss) à $\\alpha$.\n\n::: {#e11616cd .cell execution_count=8}\n``` {.python .cell-code}\nfrom scipy import stats\ndef gaussian_var(PnL, seuil):\n    mean_PnL = np.mean(PnL)\n    sd_PnL = np.std(PnL)\n    VaR = - mean_PnL + sd_PnL * stats.norm.ppf(seuil)\n    return VaR\n\nseuil = 0.99\nVaR_gaussienne = gaussian_var(train_close['log_return'], seuil)\n\nprint(f\"La VaR à horizon 1 jour est de {round(VaR_gaussienne, 4)}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLa VaR à horizon 1 jour est de 0.0325\n```\n:::\n:::\n\n\nLa VaR à horizon 1 jour est de 0.0325€, ce qui signifie que la perte maximale du portefeuille est de 0.0325€ en un jour. \n\nSur 10 jours, la VaR est de $VaR_{1j} \\times \\sqrt{10}=$ 0.1029€.\n\n::: {#b65a5006 .cell execution_count=9}\n``` {.python .cell-code}\n# Plot histogram of returns\nplt.hist(train_close[\"log_return\"], bins=50, density=True, alpha=0.7)\n\n# Plot VaR line\nplt.axvline(x=-VaR_gaussienne, color=\"red\", linestyle=\"--\", linewidth=2)\nplt.axvline(x=0, color=\"grey\",  linewidth=1)\n\n# Add labels and title\nplt.xlabel(\"Returns\")\nplt.ylabel(\"Frequency\")\nplt.title(f\"Gaussian VaR at {seuil * 100}%, Var: {VaR_gaussienne:.4f}\")\n\n# Show the plot\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](VaR_eg_files/figure-html/cell-9-output-1.png){width=585 height=449}\n:::\n:::\n\n\n### Backtesting\n\nPour backtester la VaR, nous allons comparer dans l'échantillon test les rendements logarithmiques du portefeuille avec la VaR à horizon 1 jour. Si le rendement est inférieur à la VaR, alors la VaR est violée et celà correspond à une exception.\n\n::: {#5f351533 .cell execution_count=10}\n``` {.python .cell-code}\nplt.plot(ts_close.index[0:train_size], train_close['log_return'], label=\"historical train log returns\", color = 'gray')\nplt.plot(ts_close.index[train_size:], test_close['log_return'], label=\"historical test log returns\", color = 'blue')\nplt.plot(ts_close.index[train_size:], [-VaR_gaussienne for i in range(test_size)], label=\"gaussian VaR\", color = 'red')\nlist_exceptions_gaus = [i for i in range(len(test_close['log_return'])) if test_close['log_return'][i]<-VaR_gaussienne]\nplt.scatter(test_close.index[list_exceptions_gaus], test_close['log_return'][list_exceptions_gaus], color='red', label='Exceptions')\nplt.title('CAC40')\nplt.ylabel('Values')\nplt.plot()\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](VaR_eg_files/figure-html/cell-10-output-1.png){width=623 height=431}\n:::\n:::\n\n\nNous pouvons compter le nombre d'exceptions pour la VaR à horizon 1 jour et en déduisons que le taux d'exception est 1.38%.\n\n::: {#ff932c06 .cell execution_count=11}\n``` {.python .cell-code}\nround((len(list_exceptions_gaus)/test_size)*100,2) \n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n1.38\n```\n:::\n:::\n\n\n## VaR historique\n\n::: {#c0b8cc1c .cell execution_count=12}\n``` {.python .cell-code}\ndef historical_var(PnL, seuil):\n    return -np.percentile(PnL, (1 - seuil) * 100)\n\nVaR_historique = historical_var(train_close[\"log_return\"],seuil)\nround(VaR_historique,4)\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\n0.0404\n```\n:::\n:::\n\n\n::: {#2aa3f5f9 .cell execution_count=13}\n``` {.python .cell-code}\n# Plot histogram of returns\nplt.hist(train_close[\"log_return\"], bins=50, density=True, alpha=0.7)\n\n# Plot VaR line\nplt.axvline(x=-VaR_historique, color=\"red\", linestyle=\"--\", linewidth=2)\nplt.axvline(x=0, color=\"grey\",  linewidth=1)\n\n\n# Add labels and title\nplt.xlabel(\"Returns\")\nplt.ylabel(\"Frequency\")\nplt.title(f\"Historical VaR at {seuil * 100}% Var: {VaR_historique:.4f}\")\n\n# Show the plot\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](VaR_eg_files/figure-html/cell-13-output-1.png){width=585 height=449}\n:::\n:::\n\n\n::: {#3000cdfa .cell execution_count=14}\n``` {.python .cell-code}\nplt.plot(ts_close.index[0:train_size], train_close['log_return'], label=\"historical train log returns\", color = 'gray')\nplt.plot(ts_close.index[train_size:], test_close['log_return'], label=\"historical test log returns\", color = 'blue')\nplt.plot(ts_close.index[train_size:], [-VaR_historique for i in range(test_size)], label=\"historical VaR\", color = 'red')\nlist_exceptions_hist = [i for i in range(len(test_close['log_return'])) if test_close['log_return'][i]<-VaR_historique]\nplt.scatter(test_close.index[list_exceptions_hist], test_close['log_return'][list_exceptions_hist], color='red', label='Exceptions')\nplt.title('CAC40')\nplt.ylabel('Values')\nplt.plot()\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](VaR_eg_files/figure-html/cell-14-output-1.png){width=623 height=431}\n:::\n:::\n\n\n## VaR Monte Carlo\n\n::: {#811c6001 .cell execution_count=15}\n``` {.python .cell-code}\ndef bootstrap_var(PnL, seuil, num_simulations, alpha_IC, B):\n    VaRs_boot = np.zeros(num_simulations)\n\n    for i in range(num_simulations):\n        sample = np.random.choice(PnL, B, replace=True)\n        VaRs_boot[i] = historical_var(sample, seuil)\n\n    VaR = np.mean(VaRs_boot)\n\n    lower_bound = np.percentile(VaRs_boot, 100 * (1-alpha_IC) / 2)\n    upper_bound = np.percentile(VaRs_boot, 100 * (1 - (1-alpha_IC) / 2))\n    IC = (lower_bound, upper_bound)\n\n    return VaR, IC\n\nVaR_boostrap, IC = bootstrap_var(train_close[\"log_return\"], seuil, 5000, 0.95, train_size)\n```\n:::\n\n\n::: {#868d6db2 .cell execution_count=16}\n``` {.python .cell-code}\nplt.plot(ts_close.index[0:train_size], train_close['log_return'], label=\"historical train log returns\", color = 'gray')\nplt.plot(ts_close.index[train_size:], test_close['log_return'], label=\"historical test log returns\", color = 'blue')\nplt.plot(ts_close.index[train_size:], [-VaR_boostrap for i in range(test_size)], label=\"Non parametric Bootstrap VaR\", color = 'red')\nlist_exceptions_np_boot = [i for i in range(len(test_close['log_return'])) if test_close['log_return'][i]<-VaR_boostrap]\nplt.scatter(test_close.index[list_exceptions_np_boot], test_close['log_return'][list_exceptions_np_boot], color='red', label='Exceptions')\nplt.title('CAC40')\nplt.ylabel('Values')\nplt.plot()\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](VaR_eg_files/figure-html/cell-16-output-1.png){width=623 height=431}\n:::\n:::\n\n\n",
    "supporting": [
      "VaR_eg_files"
    ],
    "filters": [],
    "includes": {}
  }
}